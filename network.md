#	网络知识梳理

##	1.TCP/IP

	下一层对上一层而言是透明的，传输在每一层是对等的。


	网络层提供了**主机之间**的逻辑通信；
	运输层提供了**运行在不同主机上的进程之间**的逻辑通信。


-----------

###	应用层


####	DNS		

	DNS协议运行在UDP之上，使用53端口。

	DNS是：
		1.	由分层的DNS服务器实现的分布式数据库；
		2.	使得主机能够查询分布式数据库的应用层协议。

	域名系统，将某一域名映射为对应的IP地址

	解析过程：

		1.	同一台用户主机上运行着DNS英勇的客户端；
		2.	浏览器从上述URL中抽取主机名，并传给客户端；
		3.	DNS客户向服务器发送包含主机名的请求；
		4.	客户最终收到回答报文，其中会包含主机名的IP；
		5.	一旦浏览器接收到来自DNS的该IP地址，向IP地址的80端口发起TCP连接。


#####	名字空间

#####	指针查询

	本地	-》		DNS服务器逐级查找

#####	缓存

	在第一次查询到某个网站的IP之后，将其存储。
	（在有效时间TTL之内）再次访问该域名直接从缓存中读取即可。

	浏览器缓存	->	操作系统缓存	->	DNS服务器递归查询


####	FTP		
	了解。
	
	控制连接+数据连接


####	SMTP	
	
	电子邮件的主要协议，建立在TCP之上。

	组成：
		1.	用户代理	user agent
		2.	邮件服务器	mail server
		3.	简单邮件传输协议	SMTP

	一般直接连接，不经过中转


####	HTTP

	是Web的核心，建立在TCP之上。

#####	报文

	请求：
		请求行	（方法、URL、HTTP版本）
		首部行


#####	请求响应

#####	状态码	
			
#####	web	： 缓存和cookie

cookie：
		1.	在http响应报文中的一个cookie首部行；
		2.	在http请求报文中的一个cookie首部行；
		3.	在用户端系统中保留有一个cookie文件，并由用户的浏览器进行管理；
		4.	位于Web站点的一个后端数据库。

	cookie可以对用户进行标记，简化用户购物等活动。

缓存：
	web缓存器（web cache）也叫代理服务器（proxy server），是能代表初始web服务器来满足http请求的网络实体。


	部署web缓存器的原因：
		*	web缓存器可以大大减少对客户请求的响应时间（尤其是当客户与初始服务器之间的瓶颈贷款远远低于客户与web缓存器之间的瓶颈带宽）；
		*	web缓存器可以大大减少一个机构的接入链路到因特网的通信量。


####	HTTPS
	对HTTP进行了加密

	详细握手过程



-----


###	传输层

	UDP和TCP最基本的责任是将两个端系统之间Ip的交付服务扩展为运行在端系统上的两个进程之间的交付服务。

	**多路分解与多路复用**将主机间的交付扩展到了进程间的交付。

	运输层最低限度的服务：
		1.	进程到进程的数据交付；
		2.	差错检验。



	主机上的每个套接字能够分配一个端口号，当报文段到达主机时，运输层检查报文段中的目的端口号，并将其定向到相应的套接字。

	一个UDP套接字是由一个二元组标志的，包含一个目的IP地址和一个目的端口号。

	一个TCP套接字由一个四元组标志，包含：源IP，源端口，目的IP，目的端口。

####	UDP（用户数据报协议）		
	
	UDP提供不可靠、无连接的服务。只能满足最低限度要求。与IP一样，不可靠。

首部大小：	8字节

#####	优缺点
优点：
	*	关于发送什么数据以及何时发送数据的应用层控制更为精密；
	*	无需连接建立；
	*	无连接状态；
	*	分组首部开销小。

缺点：
	*	缺乏拥塞控制可能导致发送方和接收方之间的高丢包率。

#####	报文结构

	源端口2	目的端口2
	长度2	检验和2
	应用数据4*n


	首部共8字节

#####	差错检验（待补充！）


####	TCP（传输控制协议）

	提供可靠的、面向连接的服务。

	除了满足两点基本要求之外，还提供额外服务：
		可靠传输
		拥塞控制

#####	首部

![head](./TCPHEAD.png)

	源端口(16) + 目的端口(16) + 
	序号(32) + 确认号(32) + 
	首部长度(4) + 可选与变长字段(6) + 标志字段(6) + 接收窗口(16) + 因特网检验和(16) + 紧急数据指针(16) + 
	选项(首部长度*32) + 
	数据

#####	连接管理

######	建立连接：三次握手

1. 	客户端发出SYN报文段（不包含数据，SYN标志位置为1，带一个随机选择的初始序号ccc）；
2. 	服务器相应一个SYN ACK报文段（不包含数据，SYN置为1，选择自己的初始序号SSS，ACK置为1，确认字段号为初始序号ccc+1）；
3. 	确认报文段（可以包含数据，SYN为0，ACK为1，确认字为SSS+1）。

完成，连接建立。


######	断开连接：四次挥手

1. 	客户端发出关闭指令：向服务器发送一个报文段(FINbit=1，seq=x )；
2. 	服务器接收到后，回送一个确认报文段（ACKbit=1, ACKnum=x+1）；
3. 	服务器向客户发送FIN报文段(FINbit=1, seq=y)；
4. 	客户收到后对其确认(ACKbit=1, ACKnum=y+1)。

完成，连接释放。



######		客户TCP的状态序列

	closed	（发起链接）	--发送SYN--〉	SYN——SENT	--接收SYN&ACK，发送ACK--》		ESTABLISHED		--发送FIN-〉	（客户发起关闭请求）FIN——WAIT——1	

	--接受ACK，不发送--》	FIN——WAIT——2	--接受FIN，发送ACK--〉	TIME——WAIT	--等待30秒--》	CLOSED


######		服务TCP的状态序列

	CLOSED	--创建一个监听套接字--》	LISTEN	--接受SYN并发送SYN&ACK--〉	SYN——RCVD	--接受ACK，不发送--》	ESTABLISHED	

	--接受FIN，发送ACK--〉	CLOSE——WAIT	--发送FIN--》	LAST——ACK	--接收ACK，不发送--〉	CLOSED



#####	流量控制

TCP的每一侧主机都设置了接受缓存。

TCP通过让发送方维持一个接收窗口来提供流量控制。	接受窗口指示发送方：对方还有多少可用的缓存空间。


由于TCP不允许已经分配的缓存溢出：	$	LastByteRcvd - LastByteRead \leq RcvBuffer $

接受窗口用rwnd表示：$	rwnd = RcvBuffer - [ LastByteRcvd - LastByteRead  ]	$

在主机A整个生命周期内：
$$
	LastByteSent - LastByteAcked \leq rwnd
$$


TCP仅当它有数据或有确认要发时才会发送数据给主机A。


TCP要求：当主机B接受窗口为0时，主机A会继续发送只有一个字节的报文段，接受方会确认并开始清空缓存区，确认报文里会包含非零的rwnd值。


#####	超时重传









		特点、	
			首部、	
			连接控制	三次握手、四次挥手、同时打开、同时关闭、半关闭
			流量控制	滑动窗口、慢启动、拥塞避免、快速重传和快速恢复
			超时重传（四个计时器）


#####	可靠传输
	TCP在IP的尽力而为服务之上创建了可靠传输服务。

三个重要事件：

1.	从上层应用接收数据
	TCP从应用程序接收数据，将数据封装在一个报文段中，并把该报文段交给IP；

2.	超时
	TCP通过重传引起超时的报文段来响应超时事件，然后重启定时器；

3.	收到ACK
	到达一个含有ACK值的报文段，TCP将ACK的值`y`与它的变量`SendBase`比较；sendbase存储的是最早未被确认的字节的序号。


？？？
TCP采用累计确认的方式：y确认了之前的所有编号都已收到，如果y>SendBase意味着ACK是在确认一个或多个先前未被确认的报文段，因此发送方会更新SendBase，如果仍有未确认的，还将重启定时器。
？？？


一、一些额外情况：
	
1.	A向B发送seq=92，长度为8字节的报文段后，等待ack=100的确认字段；但是确认报文段丢失了，所以会触发超时，然后A重传一次，由于B在之间已经接收过了，所以会丢弃该报文段，但是仍会发送一次确认报文（ACK=100）给A；

2.	A连续发送了两个报文段：第一个seq=92，长度8，第二个seq=100，长度20；假设都完好无损的到达了B，但是由于超时间隔设置的太短（或是网络太慢），确认报文还未发回来就已经超时；此时A只会重传第一个报文（seq=92的），如果在重传之后的等待过程里，收到了ACK=100和ACK=120的确认报文，则第二个报文不会再被重传；

3.	与第二种类似，A发送了两个连续的报文段：seq=92，长度8和seq=100长度20；主机B正常接收到了，并且依次发送了确认报文段ACK=100和ACK=120，但是，ACK=100丢失了，A主机只按时收到了ACK=120；此时不会触发任何重传，因为ACK采用累计确认，接收到了ACK=120的含义是：120以前的数据都已经正常收到了。



二、超时间隔加倍

	TCP每次重传都会将时间间隔翻倍！


三、快速重传

	冗余ACK就是再次确认某个报文段的ACK（发送方之前已经收到了对该报文的确认）

	如果TCP接收到了对相同数据的 3 个冗余ACK，则认为后边的数据全都丢失了！从这里开始快速重传！


四、是回退N步还是选择重传

	TCP发送方仅需要维持一**发送过但未被确认的最小序号**`SendBase`和**下一个要发送的序号**`NextSeqNum`。





####	拥塞控制原理

#####	拥塞原因及代价
	
1.	当分组的到达速率接近链路容量时，分组经历巨大的排队时延；

2.	发送方必须执行重传以补偿因为缓存溢出而丢弃的分组；
	发送方再遇到大时延时所进行的不必要重传会引起路由器利用链路带宽来转发不必要的分组副本；

3.	当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费了。


#####	TCP拥塞控制方法
	
TCP必须使用端到端拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈。


运行在发送方的TCP拥塞控制机制额外跟踪一个变量--拥塞窗口（cwnd）。
	一个发送方中未被确认的数据不会大于拥塞窗口和接受窗口的最小值：$ LastByteSent - LastByteAcked \leq \min\{cwnd, rwnd\} $


	拥塞时间会引起链路上路由器的缓存溢出，从而导致数据报被丢弃，今儿引发丢包事件，此时发送方会认为在路径上出现了拥塞。

		丢失报文意味着阻塞	--》	降低发送速率
		接收到确认报文		--〉	增加发送速率


######	TCP的拥塞控制算法
	
总结：加性增，乘性减。

	即每个RTT内cwnd线性增加（+1），出现三个冗余ACK时减半（乘0.5）。



1.	慢启动
	
	TCP链接开始时，MSS通常设置为一个很小的值。

	慢启动开始阶段，cwnd的值以一个MSS开始，每当收到一个ACK就增加1个MSS。
	（发送一个，收到一个，增加一个，变为2；发送2，受到2，增加2，变为4；。。。）

	**发送速率起始慢，但在慢启动阶段呈指数增长。**

慢启动结束的三种情况：

*	由超时指示的丢包事件：
		cwnd置为1，重新开始慢启动；
		还将ssthresh（慢启动阈值）置为拥塞窗口的一半。
	
*	直接与ssthresh相关联：
		当cwnd的值等于ssthresh时，慢启动结束，进入拥塞避免模式。

*	监测到三个冗余ACK：
		执行快速重传并进入快速恢复状态。


2.	拥塞避免

	一旦进入拥塞避免状态，cwnd的值大约是上次遇到拥塞的一半，即距离拥塞不远了！

	此时每个RTT只讲cwnd的值增加1。（从指数增长变为线性增长）

	遇到丢包事件发生，将ssthresh的值更新为cwnd的一半（收到冗余ACK也会使cwnd增加），若还收到了三个冗余ACK，接下来会进入快速恢复阶段。


3.	快速恢复
	
	对于引起TCP进入快速恢复的缺失报文段，每个冗余ACK都使cwnd的值加1个MSS。
	
	最终，当对丢失报文段的一个ACK到达时，TCP降低cwnd后进入拥塞避免状态。



	如果出现了超时，快速恢复状态执行如同慢启动和拥塞避免相同的动作，然后进入慢启动状态：
		丢包事件发生，cwnd置为1个MSS，ssthresh的值置为cwnd的一半。






-----

###	网络层
	IP提供尽力而为的服务，不可靠。

####	IP

#####	首部

#####	分片	

#####	路由表



####	ICMP

#####	报文格式

#####	查询、查错


-----

###	链路层
	
####	以太网帧格式 
	
####	MTU

####	ARP
			缓存

####	RARP

-----

##	面试常见问题



